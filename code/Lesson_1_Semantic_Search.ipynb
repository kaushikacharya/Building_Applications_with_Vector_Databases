{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Lesson 1 - Semantic Search"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Welcome to Lesson 1. \n",
    "\n",
    "To access the `requirement.txt` file, go to `File` and click on `Open`.\n",
    " \n",
    "I hope you enjoy this course!"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Import the required packages"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import warnings\n",
    "\n",
    "warnings.filterwarnings(\"ignore\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "from datasets import load_dataset\n",
    "from sentence_transformers import SentenceTransformer\n",
    "from pinecone import Pinecone, ServerlessSpec\n",
    "\n",
    "from DLAIUtils import Utils\n",
    "import DLAIUtils\n",
    "\n",
    "import os\n",
    "import time\n",
    "import torch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tqdm.auto import tqdm"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Load the Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Downloading builder script: 100%|██████████| 2.38k/2.38k [00:00<00:00, 11.1MB/s]\n",
      "Downloading readme: 100%|██████████| 5.69k/5.69k [00:00<00:00, 10.9MB/s]\n",
      "Downloading data: 100%|██████████| 58.2M/58.2M [00:04<00:00, 13.6MB/s]\n",
      "Downloading data files: 100%|██████████| 1/1 [00:04<00:00,  4.98s/it]\n",
      "Extracting data files: 100%|██████████| 1/1 [00:00<00:00, 1250.91it/s]\n",
      "Generating train split: 100%|██████████| 404290/404290 [00:16<00:00, 24683.69 examples/s]\n"
     ]
    }
   ],
   "source": [
    "dataset = load_dataset(\"quora\", split=\"train[240000:290000]\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'questions': [{'id': [207550, 351729],\n",
       "   'text': ['What is the truth of life?', \"What's the evil truth of life?\"]},\n",
       "  {'id': [33183, 351730],\n",
       "   'text': ['Which is the best smartphone under 20K in India?',\n",
       "    'Which is the best smartphone with in 20k in India?']},\n",
       "  {'id': [351731, 351732],\n",
       "   'text': ['Steps taken by Canadian government to improve literacy rate?',\n",
       "    'Can I send homemade herbal hair oil from India to US via postal or private courier services?']},\n",
       "  {'id': [37799, 94186],\n",
       "   'text': ['What is a good way to lose 30 pounds in 2 months?',\n",
       "    'What can I do to lose 30 pounds in 2 months?']},\n",
       "  {'id': [351733, 351734],\n",
       "   'text': ['Which of the following most accurately describes the translation of the graph y = (x+3)^2 -2 to the graph of y = (x -2)^2 +2?',\n",
       "    'How do you graph x + 2y = -2?']}],\n",
       " 'is_duplicate': [False, True, False, True, False]}"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dataset[:5]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's collect the questions."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "questions = []\n",
    "for record in dataset[\"questions\"]:\n",
    "    questions.extend(record[\"text\"])\n",
    "\n",
    "# Remove the duplicates\n",
    "questions = list(set(questions))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Take a peek into the questions set."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Do people really believe you can sell your soul to the devil?\n",
      "What are the most dangerous trends or practices in parenting that most parents do without noticing or realizing?\n",
      "What are the home remedies for pericoronitis?\n",
      "What is the Combined Gas Law? How is it used?\n",
      "Can alcohol stimulate height growth?\n",
      "What is this bug?\n",
      "Why aren't there so many scandals in soccer/football as there are in American Football?\n",
      "Why is it so difficult for girls to propose first?\n",
      "I feel that Lee scratch Perry has better reggae than bob marley, how about you?\n",
      "How do I convince someone to share their feelings?\n",
      "--------------------------------------------------\n",
      "Number of questions: 88919\n"
     ]
    }
   ],
   "source": [
    "print(\"\\n\".join(questions[:10]))\n",
    "print(\"-\"*50)\n",
    "print(f\"Number of questions: {len(questions)}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Check cuda and Setup the model\n",
    "\n",
    "**Note**: \"Checking cuda\" refers to checking if you have access to GPUs (faster compute). In this course, we are using CPUs. So, you might notice some code cells taking a little longer to run."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "device = \"cuda\" if torch.cuda.is_available() else \"cpu\"\n",
    "\n",
    "if device != \"cuda\":\n",
    "    print(\"Sorry no cuda\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We are using *all-MiniLM-L6-v2* sentence-transformers model that maps sentences to a 384 dimensional dense vector space."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = SentenceTransformer(model_name_or_path=\"all-MiniLM-L6-v2\", device=device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(384,)"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "query = \"which city is the most populated in the world?\"\n",
    "xq = model.encode(query)\n",
    "xq.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Setup Pinecone"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "Utils = Utils()\n",
    "PINECONE_API_KEY = Utils.get_pinecone_api_key()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pinecone = Pinecone(api_key=PINECONE_API_KEY)\n",
    "INDEX_NAME = Utils.create_dlai_index_name(index_name=\"dl-ai\")\n",
    "\n",
    "if INDEX_NAME in [index.name for index in pinecone.list_indexes()]:\n",
    "    pinecone.delete_index(name=INDEX_NAME)\n",
    "\n",
    "print(INDEX_NAME)\n",
    "\n",
    "pinecone.create_index(\n",
    "    name=INDEX_NAME,\n",
    "    dimension=model.get_sentence_embedding_dimension(),\n",
    "    spec=ServerlessSpec(cloud=\"aws\", region=\"us-west-2\"),\n",
    "    metric=\"cosine\"\n",
    ")\n",
    "\n",
    "index = pinecone.Index(name=INDEX_NAME)\n",
    "print(index)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Create Embeddings and Upsert to Pinecone"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 50/50 [01:05<00:00,  1.31s/it]\n"
     ]
    }
   ],
   "source": [
    "batch_size = 200\n",
    "vector_limit = 10000\n",
    "\n",
    "questions = questions[:vector_limit]\n",
    "\n",
    "import json\n",
    "\n",
    "for i in tqdm(range(0, len(questions), batch_size)):\n",
    "    # Find end of batch\n",
    "    i_end = min(i+batch_size, len(questions))\n",
    "    # Create IDs batch\n",
    "    ids = [str(x) for x in range(i, i_end)]\n",
    "    # Create metadata batch\n",
    "    metadatas = [{\"text\": text} for text in questions[i: i_end]]\n",
    "    # Create embeddings\n",
    "    xc = model.encode(questions[i: i_end])\n",
    "    # Create records list for upsert\n",
    "    records = zip(ids, xc, metadatas)\n",
    "    # upsert to Pinecone\n",
    "    index.upsert(vectors=records)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'dimension': 384,\n",
       " 'index_fullness': 0.0,\n",
       " 'namespaces': {'': {'vector_count': 10000}},\n",
       " 'total_vector_count': 10000}"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "index.describe_index_stats()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Run your Query"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Small helper function so we can repeat queries later\n",
    "def run_query(query):\n",
    "    # query embedding\n",
    "    embedding = model.encode(query).tolist()\n",
    "    \n",
    "    results = index.query(vector=embedding, top_k=10, include_metadata=True, include_values=False)\n",
    "\n",
    "    for result in results[\"matches\"]:\n",
    "        print(f'{round(result[\"score\"], 2)}: {result[\"metadata\"][\"text\"]}')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.66: Which is the best city in the world to travel?\n",
      "0.64: Which city has the most museums per capita?\n",
      "0.61: How's the world's population determined?\n",
      "0.6: What percentage of the world's population lives in developed countries?\n",
      "0.55: Where will the biggest increases in population come from the next 20 years?\n",
      "0.55: About 50% of the world population is concentrated between the latitudes of?\n",
      "0.54: What are the largest slums in the world?\n",
      "0.53: What are the world`s deadliest tourist destinations?\n",
      "0.53: Which is the top worst country in the world?\n",
      "0.52: Which are the worst cities of India?\n"
     ]
    }
   ],
   "source": [
    "run_query(\"which city has the highest population in the world?\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.52: How do you make shepherd's pie?\n",
      "0.52: How do you bake air-dry clay?\n",
      "0.51: What are some ways to make Shepherd's pie?\n",
      "0.5: What does red velvet cake taste like?\n",
      "0.49: How do you make whipped cream without heavy cream?\n",
      "0.47: How do I make rice?\n",
      "0.47: Where can I find delicious cupcakes at Gold Coast?\n",
      "0.46: Where can I get custom decorated cakes for any occasion at Gold Coast?\n",
      "0.46: Why is banana bread considered a bread and not a cake?\n",
      "0.45: Where can I get very nice and original flavor cupcakes in Gold Coast?\n"
     ]
    }
   ],
   "source": [
    "query = \"how do i make chocolate cake?\"\n",
    "run_query(query)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "py3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.14"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
